{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared\n",
      "Total faces:  89\n",
      "Total labels:  89\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "#import OpenCV module\n",
    "import cv2\n",
    "#import os module for reading training data directories and paths\n",
    "import os\n",
    "#import numpy to convert python lists to numpy arrays as \n",
    "#it is needed by OpenCV face recognizers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "#there is no label 0 in our training data so subject name for index/label 0 is empty\n",
    "subjects = ['ben_afflek', 'elton_john', 'jerry_seinfeld', 'madonna', 'mindy_kaling']\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "#function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('C:/Users/DELL/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    #return only the face part of the image\n",
    "    return gray[y:y+w, x:x+h], faces[0]\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "# of faces and another list of labels for each face\n",
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------STEP-1--------\n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #list to hold all subject faces\n",
    "    faces = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "    \n",
    "    #let's go through each directory and read images within it\n",
    "    for i, dir_name in enumerate(dirs):\n",
    "        \n",
    "                    \n",
    "        \n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        \n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #ignore system files like .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            #build image path\n",
    "            #sample image path = training-data/s1/1.pgm\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #read image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #display an image window to show the image \n",
    "            cv2.imshow(\"Training on image...\", cv2.resize(image, (400, 500)))\n",
    "            cv2.waitKey(100)\n",
    "            \n",
    "            #detect face\n",
    "            face, rect = detect_face(image)\n",
    "            \n",
    "            \n",
    "            if face is not None:\n",
    "                #add face to list of faces\n",
    "                faces.append(face)\n",
    "                #add label for this face\n",
    "                labels.append(i)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return faces, np.array(labels)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\train\")\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#print total faces and labels\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))\n",
    "\n",
    "\n",
    "# This was probably the boring part, right? Don't worry, the fun stuff is coming up next. It's time to train our own face recognizer so that once trained it can recognize new faces of the persons it was trained on. Read? Ok then let's train our face recognizer. \n",
    "\n",
    "# ### Train Face Recognizer\n",
    "\n",
    "# As we know, OpenCV comes equipped with three face recognizers.\n",
    "# \n",
    "# 1. EigenFace Recognizer: This can be created with `cv2.face.createEigenFaceRecognizer()`\n",
    "# 2. FisherFace Recognizer: This can be created with `cv2.face.createFisherFaceRecognizer()`\n",
    "# 3. Local Binary Patterns Histogram (LBPH): This can be created with `cv2.face.LBPHFisherFaceRecognizer()`\n",
    "# \n",
    "# I am going to use LBPH face recognizer but you can use any face recognizer of your choice. No matter which of the OpenCV's face recognizer you use the code will remain the same. You just have to change one line, the face recognizer initialization line given below. \n",
    "\n",
    "# In[6]:\n",
    "\n",
    "#create our LBPH face recognizer \n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "#or use EigenFaceRecognizer by replacing above line with \n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "#or use FisherFaceRecognizer by replacing above line with \n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "\n",
    "# Now that we have initialized our face recognizer and we also have prepared our training data, it's time to train the face recognizer. We will do that by calling the `train(faces-vector, labels-vector)` method of face recognizer. \n",
    "\n",
    "# In[7]:\n",
    "\n",
    "#train our face recognizer of our training faces\n",
    "face_recognizer.train(faces, labels)\n",
    "\n",
    "face_recognizer.write('trained.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting images...\n",
      "Prediction complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "#function to draw rectangle on image \n",
    "#according to given (x, y) coordinates and \n",
    "#given width and heigh\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trained.yml')\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "#function to draw text on give image starting from\n",
    "#passed (x, y) coordinates. \n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "#this function recognizes the person in image passed\n",
    "#and draws a rectangle around detected face with name of the \n",
    "#subject\n",
    "def predict(test_img):\n",
    "    #make a copy of the image as we don't want to chang original image\n",
    "    img = test_img.copy()\n",
    "    #detect face from the image\n",
    "    face, rect = detect_face(img)\n",
    "\n",
    "    #predict the image using our face recognizer \n",
    "    label, confidence = face_recognizer.predict(face)\n",
    "    #get name of respective label returned by face recognizer\n",
    "    label_text = subjects[label]\n",
    "    \n",
    "    #draw a rectangle around face detected\n",
    "    draw_rectangle(img, rect)\n",
    "    #draw name of predicted person\n",
    "    draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Now that we have the prediction function well defined, next step is to actually call this function on our test images and display those test images to see if our face recognizer correctly recognized them. So let's do it. This is what we have been waiting for. \n",
    "\n",
    "# In[10]:\n",
    "\n",
    "print(\"Predicting images...\")\n",
    "\n",
    "#load test images\n",
    "test_img1 = cv2.imread(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\Special_test\\\\0.jpg\")\n",
    "test_img2 = cv2.imread(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\Special_test\\\\1.jpg\")\n",
    "test_img3 = cv2.imread(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\Special_test\\\\5.jpg\")\n",
    "test_img4 = cv2.imread(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\Special_test\\\\3.jpg\")\n",
    "test_img5 = cv2.imread(\"C:\\\\Users\\\\DELL\\\\face_model\\\\Research 1\\\\Special_test\\\\4.jpg\")\n",
    "\n",
    "#perform a prediction\n",
    "predicted_img1 = predict(test_img1)\n",
    "predicted_img2 = predict(test_img2)\n",
    "predicted_img3 = predict(test_img3)\n",
    "predicted_img4 = predict(test_img4)\n",
    "predicted_img5 = predict(test_img5)\n",
    "print(\"Prediction complete\")\n",
    "\n",
    "#display both images\n",
    "cv2.imshow(\"1\", cv2.resize(predicted_img1, (400, 500)))\n",
    "cv2.imshow(\"2\", cv2.resize(predicted_img2, (400, 500)))\n",
    "cv2.imshow(\"3\", cv2.resize(predicted_img3, (400, 500)))\n",
    "cv2.imshow(\"4\", cv2.resize(predicted_img4, (400, 500)))\n",
    "cv2.imshow(\"5\", cv2.resize(predicted_img5, (400, 500)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(2)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(3)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(4)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
